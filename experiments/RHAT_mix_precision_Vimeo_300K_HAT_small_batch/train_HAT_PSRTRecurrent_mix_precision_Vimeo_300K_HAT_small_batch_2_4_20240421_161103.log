2024-04-21 16:11:03,258 INFO: 
                ____                _       _____  ____
               / __ ) ____ _ _____ (_)_____/ ___/ / __ \
              / __  |/ __ `// ___// // ___/\__ \ / /_/ /
             / /_/ // /_/ /(__  )/ // /__ ___/ // _, _/
            /_____/ \__,_//____//_/ \___//____//_/ |_|
     ______                   __   __                 __      __
    / ____/____   ____   ____/ /  / /   __  __ _____ / /__   / /
   / / __ / __ \ / __ \ / __  /  / /   / / / // ___// //_/  / /
  / /_/ // /_/ // /_/ // /_/ /  / /___/ /_/ // /__ / /<    /_/
  \____/ \____/ \____/ \____/  /_____/\____/ \___//_/|_|  (_)
    
Version Information: 
	BasicSR: 1.4.2
	PyTorch: 1.9.1+cu111
	TorchVision: 0.10.1+cu111
2024-04-21 16:11:03,258 INFO: 
  name: HAT_PSRTRecurrent_mix_precision_Vimeo_300K_HAT_small_batch_2_4
  model_type: RecurrentMixPrecisionRTModel
  scale: 4
  num_gpu: 1
  manual_seed: 0
  find_unused_parameters: False
  use_static_graph: True
  datasets:[
    train:[
      name: Vimeo90K
      type: Vimeo90KRecurrentDataset
      dataroot_gt: /home/rtx3090ti-12f-1-vtrg/Desktop/bubble/RethinkVSRAlignment/data/vimeo90k/GT
      dataroot_lq: /home/rtx3090ti-12f-1-vtrg/Desktop/bubble/RethinkVSRAlignment/data/vimeo90k/BIx4
      meta_info_file: /home/rtx3090ti-12f-1-vtrg/Desktop/bubble/RethinkVSRAlignment/data/meta_info_Vimeo90K_train_GT.txt
      io_backend:[
        type: disk
      ]
      num_frame: -1
      gt_size: 256
      interval_list: [1]
      random_reverse: False
      use_hflip: True
      use_rot: True
      flip_sequence: True
      use_shuffle: True
      num_worker_per_gpu: 6
      batch_size_per_gpu: 2
      dataset_enlarge_ratio: 2
      prefetch_mode: None
      phase: train
      scale: 4
    ]
    val:[
      name: Vid4
      type: VideoRecurrentTestDataset
      dataroot_gt: /home/rtx3090ti-12f-1-vtrg/Desktop/bubble/RethinkVSRAlignment/data/Vid4/GT
      dataroot_lq: /home/rtx3090ti-12f-1-vtrg/Desktop/bubble/RethinkVSRAlignment/data/Vid4/BIx4
      cache_data: True
      io_backend:[
        type: disk
      ]
      num_frame: -1
      phase: val
      scale: 4
    ]
  ]
  network_g:[
    type: BasicRecurrentHAT
    mid_channels: 64
    embed_dim: 64
    depths: [4, 4, 4]
    num_heads: [4, 4, 4]
    window_size: [3, 8, 8]
    num_frames: 3
    cpu_cache_length: 100
    is_low_res_input: True
    spynet_path: experiments/pretrained_models/flownet/spynet_sintel_final-3d2a1287.pth
  ]
  path:[
    pretrain_network_g: experiments/HAT_PSRTRecurrent_mix_precision_Vimeo_300K_HAT_small_batch_2_2/models/net_g_45000.pth
    strict_load_g: True
    resume_state: None
    experiments_root: /home/rtx3090ti-12f-1-vtrg/Desktop/bubble/RethinkVSRAlignment/experiments/HAT_PSRTRecurrent_mix_precision_Vimeo_300K_HAT_small_batch_2_4
    models: /home/rtx3090ti-12f-1-vtrg/Desktop/bubble/RethinkVSRAlignment/experiments/HAT_PSRTRecurrent_mix_precision_Vimeo_300K_HAT_small_batch_2_4/models
    training_states: /home/rtx3090ti-12f-1-vtrg/Desktop/bubble/RethinkVSRAlignment/experiments/HAT_PSRTRecurrent_mix_precision_Vimeo_300K_HAT_small_batch_2_4/training_states
    log: /home/rtx3090ti-12f-1-vtrg/Desktop/bubble/RethinkVSRAlignment/experiments/HAT_PSRTRecurrent_mix_precision_Vimeo_300K_HAT_small_batch_2_4
    visualization: /home/rtx3090ti-12f-1-vtrg/Desktop/bubble/RethinkVSRAlignment/experiments/HAT_PSRTRecurrent_mix_precision_Vimeo_300K_HAT_small_batch_2_4/visualization
  ]
  train:[
    ema_decay: 0.999
    optim_g:[
      type: Adam
      lr: 5e-05
      weight_decay: 0
      betas: [0.9, 0.99]
    ]
    scheduler:[
      type: CosineAnnealingRestartLR
      periods: [65000]
      restart_weights: [1]
      eta_min: 1e-07
    ]
    total_iter: 65000
    warmup_iter: -1
    fix_flow: -1
    flow_lr_mul: 0.25
    pixel_opt:[
      type: CharbonnierLoss
      loss_weight: 1.0
      reduction: mean
    ]
  ]
  val:[
    val_freq: 5000.0
    save_img: False
    metrics:[
      psnr:[
        type: calculate_psnr
        crop_border: 0
        test_y_channel: True
      ]
    ]
  ]
  logger:[
    print_freq: 100
    save_checkpoint_freq: 2000.0
    use_tb_logger: True
    wandb:[
      project: None
      resume_id: None
    ]
  ]
  dist_params:[
    backend: nccl
    port: 29500
  ]
  dist: True
  rank: 0
  world_size: 1
  auto_resume: False
  is_train: True
  root_path: /home/rtx3090ti-12f-1-vtrg/Desktop/bubble/RethinkVSRAlignment

2024-04-21 16:11:03,342 INFO: Random reverse is False.
2024-04-21 16:11:03,342 INFO: Dataset [Vimeo90KRecurrentDataset] - Vimeo90K is built.
2024-04-21 16:11:03,342 INFO: Training statistics:
	Number of train images: 64612
	Dataset enlarge ratio: 2
	Batch size per gpu: 2
	World size (gpu number): 1
	Require iter number per epoch: 64612
	Total epochs: 2; iters: 65000.
2024-04-21 16:11:03,342 INFO: Generate data info for VideoTestDataset - Vid4
2024-04-21 16:11:03,342 INFO: Cache calendar for VideoTestDataset...
2024-04-21 16:11:03,827 INFO: Cache city for VideoTestDataset...
2024-04-21 16:11:04,208 INFO: Cache foliage for VideoTestDataset...
2024-04-21 16:11:04,659 INFO: Cache walk for VideoTestDataset...
2024-04-21 16:11:05,094 INFO: Dataset [VideoRecurrentTestDataset] - Vid4 is built.
2024-04-21 16:11:05,094 INFO: Number of val images/folders in Vid4: 4
2024-04-21 16:11:05,165 INFO: Network [BasicRecurrentHAT] is created.
2024-04-21 16:11:07,087 INFO: Network: BasicRecurrentHAT, with parameters: 6,129,967
2024-04-21 16:11:07,088 INFO: BasicRecurrentHAT(
  (conv_before_upsample): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (spynet): SpyNet(
    (basic_module): ModuleList(
      (0): BasicModule(
        (basic_module): Sequential(
          (0): Conv2d(8, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
          (1): ReLU()
          (2): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
          (3): ReLU()
          (4): Conv2d(64, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
          (5): ReLU()
          (6): Conv2d(32, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
          (7): ReLU()
          (8): Conv2d(16, 2, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        )
      )
      (1): BasicModule(
        (basic_module): Sequential(
          (0): Conv2d(8, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
          (1): ReLU()
          (2): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
          (3): ReLU()
          (4): Conv2d(64, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
          (5): ReLU()
          (6): Conv2d(32, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
          (7): ReLU()
          (8): Conv2d(16, 2, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        )
      )
      (2): BasicModule(
        (basic_module): Sequential(
          (0): Conv2d(8, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
          (1): ReLU()
          (2): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
          (3): ReLU()
          (4): Conv2d(64, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
          (5): ReLU()
          (6): Conv2d(32, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
          (7): ReLU()
          (8): Conv2d(16, 2, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        )
      )
      (3): BasicModule(
        (basic_module): Sequential(
          (0): Conv2d(8, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
          (1): ReLU()
          (2): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
          (3): ReLU()
          (4): Conv2d(64, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
          (5): ReLU()
          (6): Conv2d(32, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
          (7): ReLU()
          (8): Conv2d(16, 2, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        )
      )
      (4): BasicModule(
        (basic_module): Sequential(
          (0): Conv2d(8, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
          (1): ReLU()
          (2): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
          (3): ReLU()
          (4): Conv2d(64, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
          (5): ReLU()
          (6): Conv2d(32, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
          (7): ReLU()
          (8): Conv2d(16, 2, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        )
      )
      (5): BasicModule(
        (basic_module): Sequential(
          (0): Conv2d(8, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
          (1): ReLU()
          (2): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
          (3): ReLU()
          (4): Conv2d(64, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
          (5): ReLU()
          (6): Conv2d(32, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
          (7): ReLU()
          (8): Conv2d(16, 2, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        )
      )
    )
  )
  (conv_first): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (patch_align): ModuleDict(
    (backward_1): MFHAT(
      (conv_first): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv_first_feat): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed(
        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
      (patch_unembed): PatchUnEmbed()
      (pos_drop): Dropout(p=0.0, inplace=False)
      (layers): ModuleList(
        (0): RHAG(
          (residual_group): AttentionBlocks(
            dim=64, input_resolution=(64, 64), depth=4
            (blocks): ModuleList(
              (0): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(0, 0, 0), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): Identity()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(3, 4, 4), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (2): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(0, 0, 0), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (3): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(3, 4, 4), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (overlap_attn): OCAB(
              (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (qkv): Linear(in_features=64, out_features=192, bias=True)
              (kv_partition): Overlapping_window_partition()
              (softmax): Softmax(dim=-1)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=64, out_features=64, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (drop_path): Identity()
              (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=64, out_features=128, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=128, out_features=64, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (patch_embed): PatchEmbed()
          (patch_unembed): PatchUnEmbed()
        )
        (1): RHAG(
          (residual_group): AttentionBlocks(
            dim=64, input_resolution=(64, 64), depth=4
            (blocks): ModuleList(
              (0): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(0, 0, 0), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(3, 4, 4), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (2): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(0, 0, 0), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (3): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(3, 4, 4), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (overlap_attn): OCAB(
              (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (qkv): Linear(in_features=64, out_features=192, bias=True)
              (kv_partition): Overlapping_window_partition()
              (softmax): Softmax(dim=-1)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=64, out_features=64, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (drop_path): Identity()
              (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=64, out_features=128, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=128, out_features=64, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (patch_embed): PatchEmbed()
          (patch_unembed): PatchUnEmbed()
        )
        (2): RHAG(
          (residual_group): AttentionBlocks(
            dim=64, input_resolution=(64, 64), depth=4
            (blocks): ModuleList(
              (0): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(0, 0, 0), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(3, 4, 4), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (2): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(0, 0, 0), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (3): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(3, 4, 4), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (overlap_attn): OCAB(
              (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (qkv): Linear(in_features=64, out_features=192, bias=True)
              (kv_partition): Overlapping_window_partition()
              (softmax): Softmax(dim=-1)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=64, out_features=64, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (drop_path): Identity()
              (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=64, out_features=128, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=128, out_features=64, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (patch_embed): PatchEmbed()
          (patch_unembed): PatchUnEmbed()
        )
      )
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (conv_after_body): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)
      (conv_before_upsample): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (forward_1): MFHAT(
      (conv_first): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv_first_feat): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed(
        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
      (patch_unembed): PatchUnEmbed()
      (pos_drop): Dropout(p=0.0, inplace=False)
      (layers): ModuleList(
        (0): RHAG(
          (residual_group): AttentionBlocks(
            dim=64, input_resolution=(64, 64), depth=4
            (blocks): ModuleList(
              (0): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(0, 0, 0), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): Identity()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(3, 4, 4), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (2): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(0, 0, 0), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (3): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(3, 4, 4), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (overlap_attn): OCAB(
              (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (qkv): Linear(in_features=64, out_features=192, bias=True)
              (kv_partition): Overlapping_window_partition()
              (softmax): Softmax(dim=-1)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=64, out_features=64, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (drop_path): Identity()
              (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=64, out_features=128, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=128, out_features=64, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (patch_embed): PatchEmbed()
          (patch_unembed): PatchUnEmbed()
        )
        (1): RHAG(
          (residual_group): AttentionBlocks(
            dim=64, input_resolution=(64, 64), depth=4
            (blocks): ModuleList(
              (0): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(0, 0, 0), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(3, 4, 4), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (2): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(0, 0, 0), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (3): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(3, 4, 4), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (overlap_attn): OCAB(
              (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (qkv): Linear(in_features=64, out_features=192, bias=True)
              (kv_partition): Overlapping_window_partition()
              (softmax): Softmax(dim=-1)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=64, out_features=64, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (drop_path): Identity()
              (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=64, out_features=128, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=128, out_features=64, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (patch_embed): PatchEmbed()
          (patch_unembed): PatchUnEmbed()
        )
        (2): RHAG(
          (residual_group): AttentionBlocks(
            dim=64, input_resolution=(64, 64), depth=4
            (blocks): ModuleList(
              (0): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(0, 0, 0), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(3, 4, 4), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (2): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(0, 0, 0), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (3): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(3, 4, 4), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (overlap_attn): OCAB(
              (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (qkv): Linear(in_features=64, out_features=192, bias=True)
              (kv_partition): Overlapping_window_partition()
              (softmax): Softmax(dim=-1)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=64, out_features=64, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (drop_path): Identity()
              (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=64, out_features=128, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=128, out_features=64, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (patch_embed): PatchEmbed()
          (patch_unembed): PatchUnEmbed()
        )
      )
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (conv_after_body): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)
      (conv_before_upsample): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (backward_2): MFHAT(
      (conv_first): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv_first_feat): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed(
        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
      (patch_unembed): PatchUnEmbed()
      (pos_drop): Dropout(p=0.0, inplace=False)
      (layers): ModuleList(
        (0): RHAG(
          (residual_group): AttentionBlocks(
            dim=64, input_resolution=(64, 64), depth=4
            (blocks): ModuleList(
              (0): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(0, 0, 0), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): Identity()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(3, 4, 4), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (2): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(0, 0, 0), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (3): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(3, 4, 4), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (overlap_attn): OCAB(
              (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (qkv): Linear(in_features=64, out_features=192, bias=True)
              (kv_partition): Overlapping_window_partition()
              (softmax): Softmax(dim=-1)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=64, out_features=64, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (drop_path): Identity()
              (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=64, out_features=128, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=128, out_features=64, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (patch_embed): PatchEmbed()
          (patch_unembed): PatchUnEmbed()
        )
        (1): RHAG(
          (residual_group): AttentionBlocks(
            dim=64, input_resolution=(64, 64), depth=4
            (blocks): ModuleList(
              (0): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(0, 0, 0), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(3, 4, 4), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (2): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(0, 0, 0), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (3): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(3, 4, 4), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (overlap_attn): OCAB(
              (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (qkv): Linear(in_features=64, out_features=192, bias=True)
              (kv_partition): Overlapping_window_partition()
              (softmax): Softmax(dim=-1)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=64, out_features=64, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (drop_path): Identity()
              (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=64, out_features=128, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=128, out_features=64, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (patch_embed): PatchEmbed()
          (patch_unembed): PatchUnEmbed()
        )
        (2): RHAG(
          (residual_group): AttentionBlocks(
            dim=64, input_resolution=(64, 64), depth=4
            (blocks): ModuleList(
              (0): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(0, 0, 0), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(3, 4, 4), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (2): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(0, 0, 0), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (3): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(3, 4, 4), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (overlap_attn): OCAB(
              (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (qkv): Linear(in_features=64, out_features=192, bias=True)
              (kv_partition): Overlapping_window_partition()
              (softmax): Softmax(dim=-1)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=64, out_features=64, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (drop_path): Identity()
              (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=64, out_features=128, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=128, out_features=64, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (patch_embed): PatchEmbed()
          (patch_unembed): PatchUnEmbed()
        )
      )
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (conv_after_body): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)
      (conv_before_upsample): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (forward_2): MFHAT(
      (conv_first): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv_first_feat): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed(
        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
      (patch_unembed): PatchUnEmbed()
      (pos_drop): Dropout(p=0.0, inplace=False)
      (layers): ModuleList(
        (0): RHAG(
          (residual_group): AttentionBlocks(
            dim=64, input_resolution=(64, 64), depth=4
            (blocks): ModuleList(
              (0): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(0, 0, 0), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): Identity()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(3, 4, 4), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (2): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(0, 0, 0), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (3): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(3, 4, 4), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (overlap_attn): OCAB(
              (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (qkv): Linear(in_features=64, out_features=192, bias=True)
              (kv_partition): Overlapping_window_partition()
              (softmax): Softmax(dim=-1)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=64, out_features=64, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (drop_path): Identity()
              (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=64, out_features=128, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=128, out_features=64, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (patch_embed): PatchEmbed()
          (patch_unembed): PatchUnEmbed()
        )
        (1): RHAG(
          (residual_group): AttentionBlocks(
            dim=64, input_resolution=(64, 64), depth=4
            (blocks): ModuleList(
              (0): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(0, 0, 0), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(3, 4, 4), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (2): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(0, 0, 0), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (3): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(3, 4, 4), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (overlap_attn): OCAB(
              (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (qkv): Linear(in_features=64, out_features=192, bias=True)
              (kv_partition): Overlapping_window_partition()
              (softmax): Softmax(dim=-1)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=64, out_features=64, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (drop_path): Identity()
              (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=64, out_features=128, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=128, out_features=64, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (patch_embed): PatchEmbed()
          (patch_unembed): PatchUnEmbed()
        )
        (2): RHAG(
          (residual_group): AttentionBlocks(
            dim=64, input_resolution=(64, 64), depth=4
            (blocks): ModuleList(
              (0): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(0, 0, 0), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(3, 4, 4), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (2): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(0, 0, 0), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (3): HAB(
                dim=64, input_resolution=(64, 64), num_heads=4, window_size=[3, 8, 8], shift_size=(3, 4, 4), mlp_ratio=2.0
                (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  dim=64, window_size=[3, 8, 8], num_heads=4
                  (qkv): Linear(in_features=64, out_features=192, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=64, out_features=64, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (conv_block): CAB3D(
                  (cab): Sequential(
                    (0): Conv3d(64, 21, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (1): GELU()
                    (2): Conv3d(21, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                    (3): ChannelAttention3D(
                      (attention): Sequential(
                        (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
                        (1): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (2): ReLU(inplace=True)
                        (3): Conv3d(2, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                        (4): Sigmoid()
                      )
                    )
                  )
                )
                (drop_path): DropPath()
                (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=64, out_features=128, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=128, out_features=64, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (overlap_attn): OCAB(
              (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (qkv): Linear(in_features=64, out_features=192, bias=True)
              (kv_partition): Overlapping_window_partition()
              (softmax): Softmax(dim=-1)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=64, out_features=64, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (drop_path): Identity()
              (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=64, out_features=128, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=128, out_features=64, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (patch_embed): PatchEmbed()
          (patch_unembed): PatchUnEmbed()
        )
      )
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (conv_after_body): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)
      (conv_before_upsample): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (upconv1): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upconv2): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (pixel_shuffle): PixelShuffle(upscale_factor=2)
  (conv_hr): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv_last): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (img_upsample): Upsample(scale_factor=4.0, mode=bilinear)
  (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)
)
2024-04-21 16:11:07,153 INFO: Loading BasicRecurrentHAT model from experiments/HAT_PSRTRecurrent_mix_precision_Vimeo_300K_HAT_small_batch_2_2/models/net_g_45000.pth, with param key: [params].
2024-04-21 16:11:07,285 INFO: Use Exponential Moving Average with decay: 0.999
2024-04-21 16:11:07,354 INFO: Network [BasicRecurrentHAT] is created.
2024-04-21 16:11:07,426 INFO: Loading BasicRecurrentHAT model from experiments/HAT_PSRTRecurrent_mix_precision_Vimeo_300K_HAT_small_batch_2_2/models/net_g_45000.pth, with param key: [params_ema].
2024-04-21 16:11:07,556 INFO: Loss [CharbonnierLoss] is created.
2024-04-21 16:11:07,556 INFO: Multiple the learning rate for flow network with 0.25.
2024-04-21 16:11:07,618 INFO: Using static graph. Make sure that "unused parameters" will not change during training loop.
2024-04-21 16:11:07,618 INFO: Model [RecurrentMixPrecisionRTModel] is created.
2024-04-21 16:11:12,178 INFO: Start training from epoch: 0, iter: 0
2024-04-21 16:11:17,081 INFO: Fix flow network and feature extractor for -1 iters.
2024-04-21 16:22:03,475 INFO: [HAT_P..][epoch:  0, iter:     100, lr:(5.000e-05,1.250e-05,)] [eta: 4 days, 18:05:42, time (data): 6.513 (0.051)] l_pix: 6.0927e-03 
2024-04-21 16:32:49,123 INFO: [HAT_P..][epoch:  0, iter:     200, lr:(5.000e-05,1.250e-05,)] [eta: 4 days, 19:03:41, time (data): 6.485 (0.027)] l_pix: 5.8720e-03 
2024-04-21 16:43:34,792 INFO: [HAT_P..][epoch:  0, iter:     300, lr:(5.000e-05,1.250e-05,)] [eta: 4 days, 19:16:03, time (data): 6.457 (0.003)] l_pix: 1.9613e-02 
2024-04-21 16:54:20,521 INFO: [HAT_P..][epoch:  0, iter:     400, lr:(5.000e-05,1.250e-05,)] [eta: 4 days, 19:17:03, time (data): 6.457 (0.003)] l_pix: 9.1956e-03 
2024-04-21 17:05:06,247 INFO: [HAT_P..][epoch:  0, iter:     500, lr:(4.999e-05,1.250e-05,)] [eta: 4 days, 19:13:21, time (data): 6.457 (0.003)] l_pix: 2.6718e-02 
2024-04-21 17:15:51,904 INFO: [HAT_P..][epoch:  0, iter:     600, lr:(4.999e-05,1.250e-05,)] [eta: 4 days, 19:07:10, time (data): 6.457 (0.003)] l_pix: 1.5732e-02 
2024-04-21 17:26:37,519 INFO: [HAT_P..][epoch:  0, iter:     700, lr:(4.999e-05,1.250e-05,)] [eta: 4 days, 18:59:38, time (data): 6.456 (0.002)] l_pix: 1.4976e-02 
2024-04-21 17:37:23,169 INFO: [HAT_P..][epoch:  0, iter:     800, lr:(4.998e-05,1.250e-05,)] [eta: 4 days, 18:51:19, time (data): 6.456 (0.002)] l_pix: 6.8166e-03 
2024-04-21 17:48:08,878 INFO: [HAT_P..][epoch:  0, iter:     900, lr:(4.998e-05,1.249e-05,)] [eta: 4 days, 18:42:33, time (data): 6.457 (0.003)] l_pix: 1.3344e-02 
2024-04-21 17:58:54,522 INFO: [HAT_P..][epoch:  0, iter:   1,000, lr:(4.997e-05,1.249e-05,)] [eta: 4 days, 18:33:18, time (data): 6.457 (0.003)] l_pix: 4.0641e-03 
2024-04-21 18:09:40,155 INFO: [HAT_P..][epoch:  0, iter:   1,100, lr:(4.996e-05,1.249e-05,)] [eta: 4 days, 18:23:46, time (data): 6.456 (0.003)] l_pix: 9.3617e-03 
2024-04-21 18:20:25,835 INFO: [HAT_P..][epoch:  0, iter:   1,200, lr:(4.996e-05,1.249e-05,)] [eta: 4 days, 18:14:05, time (data): 6.456 (0.002)] l_pix: 5.5123e-03 
2024-04-21 18:31:11,459 INFO: [HAT_P..][epoch:  0, iter:   1,300, lr:(4.995e-05,1.249e-05,)] [eta: 4 days, 18:04:10, time (data): 6.456 (0.002)] l_pix: 5.4197e-03 
2024-04-21 18:41:57,032 INFO: [HAT_P..][epoch:  0, iter:   1,400, lr:(4.994e-05,1.249e-05,)] [eta: 4 days, 17:54:06, time (data): 6.456 (0.002)] l_pix: 1.3089e-02 
2024-04-21 18:52:42,692 INFO: [HAT_P..][epoch:  0, iter:   1,500, lr:(4.993e-05,1.248e-05,)] [eta: 4 days, 17:44:01, time (data): 6.456 (0.002)] l_pix: 7.1784e-03 
2024-04-21 19:03:28,271 INFO: [HAT_P..][epoch:  0, iter:   1,600, lr:(4.993e-05,1.248e-05,)] [eta: 4 days, 17:33:47, time (data): 6.456 (0.002)] l_pix: 1.0501e-02 
2024-04-21 19:14:13,877 INFO: [HAT_P..][epoch:  0, iter:   1,700, lr:(4.992e-05,1.248e-05,)] [eta: 4 days, 17:23:30, time (data): 6.456 (0.002)] l_pix: 1.0433e-02 
2024-04-21 19:24:59,486 INFO: [HAT_P..][epoch:  0, iter:   1,800, lr:(4.991e-05,1.248e-05,)] [eta: 4 days, 17:13:10, time (data): 6.456 (0.002)] l_pix: 7.2955e-03 
2024-04-21 19:35:45,031 INFO: [HAT_P..][epoch:  0, iter:   1,900, lr:(4.989e-05,1.247e-05,)] [eta: 4 days, 17:02:46, time (data): 6.455 (0.002)] l_pix: 1.2614e-02 
2024-04-21 19:46:30,662 INFO: [HAT_P..][epoch:  0, iter:   2,000, lr:(4.988e-05,1.247e-05,)] [eta: 4 days, 16:52:22, time (data): 6.456 (0.002)] l_pix: 9.7986e-03 
2024-04-21 19:46:30,662 INFO: Saving models and training states.
2024-04-21 19:57:16,544 INFO: [HAT_P..][epoch:  0, iter:   2,100, lr:(4.987e-05,1.247e-05,)] [eta: 4 days, 16:42:03, time (data): 6.457 (0.002)] l_pix: 8.2354e-03 
2024-04-21 20:08:02,293 INFO: [HAT_P..][epoch:  0, iter:   2,200, lr:(4.986e-05,1.247e-05,)] [eta: 4 days, 16:31:38, time (data): 6.457 (0.002)] l_pix: 1.5421e-02 
2024-04-21 20:18:48,086 INFO: [HAT_P..][epoch:  0, iter:   2,300, lr:(4.985e-05,1.246e-05,)] [eta: 4 days, 16:21:13, time (data): 6.458 (0.003)] l_pix: 4.1301e-03 
2024-04-21 20:29:33,866 INFO: [HAT_P..][epoch:  0, iter:   2,400, lr:(4.983e-05,1.246e-05,)] [eta: 4 days, 16:10:46, time (data): 6.458 (0.003)] l_pix: 1.3609e-02 
2024-04-21 20:40:19,655 INFO: [HAT_P..][epoch:  0, iter:   2,500, lr:(4.982e-05,1.245e-05,)] [eta: 4 days, 16:00:17, time (data): 6.458 (0.003)] l_pix: 9.4051e-03 
2024-04-21 20:51:05,333 INFO: [HAT_P..][epoch:  0, iter:   2,600, lr:(4.980e-05,1.245e-05,)] [eta: 4 days, 15:49:44, time (data): 6.457 (0.003)] l_pix: 7.5832e-03 
2024-04-21 21:01:51,091 INFO: [HAT_P..][epoch:  0, iter:   2,700, lr:(4.979e-05,1.245e-05,)] [eta: 4 days, 15:39:12, time (data): 6.457 (0.003)] l_pix: 1.2454e-02 
2024-04-21 21:12:36,842 INFO: [HAT_P..][epoch:  0, iter:   2,800, lr:(4.977e-05,1.244e-05,)] [eta: 4 days, 15:28:39, time (data): 6.457 (0.003)] l_pix: 9.4305e-03 
2024-04-21 21:23:22,573 INFO: [HAT_P..][epoch:  0, iter:   2,900, lr:(4.976e-05,1.244e-05,)] [eta: 4 days, 15:18:05, time (data): 6.457 (0.003)] l_pix: 1.4026e-02 
2024-04-21 21:34:08,333 INFO: [HAT_P..][epoch:  0, iter:   3,000, lr:(4.974e-05,1.243e-05,)] [eta: 4 days, 15:07:31, time (data): 6.457 (0.002)] l_pix: 1.1460e-02 
2024-04-21 21:44:54,054 INFO: [HAT_P..][epoch:  0, iter:   3,100, lr:(4.972e-05,1.243e-05,)] [eta: 4 days, 14:56:55, time (data): 6.457 (0.003)] l_pix: 2.2409e-02 
2024-04-21 21:55:39,742 INFO: [HAT_P..][epoch:  0, iter:   3,200, lr:(4.970e-05,1.243e-05,)] [eta: 4 days, 14:46:18, time (data): 6.457 (0.003)] l_pix: 4.5121e-03 
2024-04-21 22:06:25,465 INFO: [HAT_P..][epoch:  0, iter:   3,300, lr:(4.968e-05,1.242e-05,)] [eta: 4 days, 14:35:41, time (data): 6.457 (0.003)] l_pix: 1.3551e-02 
2024-04-21 22:17:11,152 INFO: [HAT_P..][epoch:  0, iter:   3,400, lr:(4.966e-05,1.242e-05,)] [eta: 4 days, 14:25:02, time (data): 6.457 (0.003)] l_pix: 1.0119e-02 
2024-04-21 22:27:56,930 INFO: [HAT_P..][epoch:  0, iter:   3,500, lr:(4.964e-05,1.241e-05,)] [eta: 4 days, 14:14:25, time (data): 6.458 (0.002)] l_pix: 1.0707e-02 
2024-04-21 22:38:42,677 INFO: [HAT_P..][epoch:  0, iter:   3,600, lr:(4.962e-05,1.241e-05,)] [eta: 4 days, 14:03:47, time (data): 6.458 (0.002)] l_pix: 1.1474e-02 
2024-04-21 22:49:28,416 INFO: [HAT_P..][epoch:  0, iter:   3,700, lr:(4.960e-05,1.240e-05,)] [eta: 4 days, 13:53:09, time (data): 6.457 (0.002)] l_pix: 1.9772e-02 
2024-04-21 23:00:14,117 INFO: [HAT_P..][epoch:  0, iter:   3,800, lr:(4.958e-05,1.240e-05,)] [eta: 4 days, 13:42:29, time (data): 6.457 (0.002)] l_pix: 8.0413e-03 
2024-04-21 23:10:59,810 INFO: [HAT_P..][epoch:  0, iter:   3,900, lr:(4.956e-05,1.239e-05,)] [eta: 4 days, 13:31:49, time (data): 6.457 (0.002)] l_pix: 1.6292e-02 
2024-04-21 23:21:48,098 INFO: [HAT_P..][epoch:  0, iter:   4,000, lr:(4.954e-05,1.238e-05,)] [eta: 4 days, 13:21:48, time (data): 6.471 (0.002)] l_pix: 3.5143e-03 
2024-04-21 23:21:48,098 INFO: Saving models and training states.
2024-04-21 23:32:34,131 INFO: [HAT_P..][epoch:  0, iter:   4,100, lr:(4.951e-05,1.238e-05,)] [eta: 4 days, 13:11:12, time (data): 6.459 (0.002)] l_pix: 1.4693e-02 
2024-04-21 23:43:19,970 INFO: [HAT_P..][epoch:  0, iter:   4,200, lr:(4.949e-05,1.237e-05,)] [eta: 4 days, 13:00:32, time (data): 6.458 (0.002)] l_pix: 6.2688e-03 
2024-04-21 23:54:05,862 INFO: [HAT_P..][epoch:  0, iter:   4,300, lr:(4.946e-05,1.237e-05,)] [eta: 4 days, 12:49:53, time (data): 6.459 (0.003)] l_pix: 1.0683e-02 
2024-04-22 00:04:51,660 INFO: [HAT_P..][epoch:  0, iter:   4,400, lr:(4.944e-05,1.236e-05,)] [eta: 4 days, 12:39:12, time (data): 6.458 (0.003)] l_pix: 1.0411e-02 
2024-04-22 00:15:37,468 INFO: [HAT_P..][epoch:  0, iter:   4,500, lr:(4.941e-05,1.235e-05,)] [eta: 4 days, 12:28:31, time (data): 6.458 (0.003)] l_pix: 9.6529e-03 
2024-04-22 00:26:23,181 INFO: [HAT_P..][epoch:  0, iter:   4,600, lr:(4.939e-05,1.235e-05,)] [eta: 4 days, 12:17:48, time (data): 6.457 (0.003)] l_pix: 9.1476e-03 
2024-04-22 00:37:08,862 INFO: [HAT_P..][epoch:  0, iter:   4,700, lr:(4.936e-05,1.234e-05,)] [eta: 4 days, 12:07:05, time (data): 6.457 (0.002)] l_pix: 6.1463e-03 
2024-04-22 00:47:54,592 INFO: [HAT_P..][epoch:  0, iter:   4,800, lr:(4.933e-05,1.233e-05,)] [eta: 4 days, 11:56:23, time (data): 6.457 (0.002)] l_pix: 1.1338e-02 
2024-04-22 00:58:40,371 INFO: [HAT_P..][epoch:  0, iter:   4,900, lr:(4.930e-05,1.233e-05,)] [eta: 4 days, 11:45:41, time (data): 6.458 (0.002)] l_pix: 8.9795e-03 
2024-04-22 01:09:26,083 INFO: [HAT_P..][epoch:  0, iter:   5,000, lr:(4.928e-05,1.232e-05,)] [eta: 4 days, 11:34:58, time (data): 6.457 (0.003)] l_pix: 1.4356e-02 
2024-04-22 01:10:25,252 INFO: Validation Vid4
	 # psnr: 26.4002	 # calendar: 23.1107	 # city: 27.1713	 # foliage: 25.6579	 # walk: 29.6608
	    Best: 26.4002 @ 5000 iter

2024-04-22 01:21:10,268 INFO: [HAT_P..][epoch:  0, iter:   5,100, lr:(4.925e-05,1.231e-05,)] [eta: 4 days, 11:35:41, time (data): 6.452 (0.003)] l_pix: 9.2264e-03 
2024-04-22 01:31:55,453 INFO: [HAT_P..][epoch:  0, iter:   5,200, lr:(4.922e-05,1.231e-05,)] [eta: 4 days, 11:24:37, time (data): 6.452 (0.003)] l_pix: 2.3029e-02 
2024-04-22 01:42:40,636 INFO: [HAT_P..][epoch:  0, iter:   5,300, lr:(4.919e-05,1.230e-05,)] [eta: 4 days, 11:13:35, time (data): 6.452 (0.003)] l_pix: 7.6337e-03 
2024-04-22 01:53:25,839 INFO: [HAT_P..][epoch:  0, iter:   5,400, lr:(4.916e-05,1.229e-05,)] [eta: 4 days, 11:02:33, time (data): 6.452 (0.003)] l_pix: 1.7505e-02 
2024-04-22 02:04:10,984 INFO: [HAT_P..][epoch:  0, iter:   5,500, lr:(4.912e-05,1.228e-05,)] [eta: 4 days, 10:51:30, time (data): 6.452 (0.002)] l_pix: 1.4841e-02 
2024-04-22 02:14:56,149 INFO: [HAT_P..][epoch:  0, iter:   5,600, lr:(4.909e-05,1.227e-05,)] [eta: 4 days, 10:40:29, time (data): 6.452 (0.003)] l_pix: 1.8077e-02 
2024-04-22 02:25:41,344 INFO: [HAT_P..][epoch:  0, iter:   5,700, lr:(4.906e-05,1.227e-05,)] [eta: 4 days, 10:29:29, time (data): 6.452 (0.003)] l_pix: 7.5802e-03 
2024-04-22 02:36:26,585 INFO: [HAT_P..][epoch:  0, iter:   5,800, lr:(4.903e-05,1.226e-05,)] [eta: 4 days, 10:18:29, time (data): 6.452 (0.003)] l_pix: 2.7811e-02 
2024-04-22 02:47:11,791 INFO: [HAT_P..][epoch:  0, iter:   5,900, lr:(4.899e-05,1.225e-05,)] [eta: 4 days, 10:07:30, time (data): 6.452 (0.003)] l_pix: 1.2657e-02 
2024-04-22 02:57:56,954 INFO: [HAT_P..][epoch:  0, iter:   6,000, lr:(4.896e-05,1.224e-05,)] [eta: 4 days, 9:56:31, time (data): 6.452 (0.003)] l_pix: 6.9781e-03 
2024-04-22 02:57:56,954 INFO: Saving models and training states.
2024-04-22 03:08:42,227 INFO: [HAT_P..][epoch:  0, iter:   6,100, lr:(4.892e-05,1.223e-05,)] [eta: 4 days, 9:45:33, time (data): 6.451 (0.003)] l_pix: 4.4378e-03 
2024-04-22 03:19:27,460 INFO: [HAT_P..][epoch:  0, iter:   6,200, lr:(4.889e-05,1.222e-05,)] [eta: 4 days, 9:34:36, time (data): 6.452 (0.003)] l_pix: 3.7410e-03 
2024-04-22 03:30:12,665 INFO: [HAT_P..][epoch:  0, iter:   6,300, lr:(4.885e-05,1.221e-05,)] [eta: 4 days, 9:23:38, time (data): 6.452 (0.003)] l_pix: 3.2713e-03 
2024-04-22 03:40:57,763 INFO: [HAT_P..][epoch:  0, iter:   6,400, lr:(4.882e-05,1.221e-05,)] [eta: 4 days, 9:12:40, time (data): 6.451 (0.003)] l_pix: 1.2217e-02 
2024-04-22 03:51:42,926 INFO: [HAT_P..][epoch:  0, iter:   6,500, lr:(4.878e-05,1.220e-05,)] [eta: 4 days, 9:01:43, time (data): 6.451 (0.003)] l_pix: 1.5951e-02 
2024-04-22 04:02:28,057 INFO: [HAT_P..][epoch:  0, iter:   6,600, lr:(4.874e-05,1.219e-05,)] [eta: 4 days, 8:50:46, time (data): 6.451 (0.003)] l_pix: 7.5667e-03 
2024-04-22 04:13:13,322 INFO: [HAT_P..][epoch:  0, iter:   6,700, lr:(4.870e-05,1.218e-05,)] [eta: 4 days, 8:39:50, time (data): 6.452 (0.003)] l_pix: 9.0612e-03 
2024-04-22 04:23:58,533 INFO: [HAT_P..][epoch:  0, iter:   6,800, lr:(4.866e-05,1.217e-05,)] [eta: 4 days, 8:28:55, time (data): 6.452 (0.003)] l_pix: 2.1423e-02 
2024-04-22 04:34:43,689 INFO: [HAT_P..][epoch:  0, iter:   6,900, lr:(4.863e-05,1.216e-05,)] [eta: 4 days, 8:17:59, time (data): 6.452 (0.003)] l_pix: 1.0245e-02 
2024-04-22 04:45:28,857 INFO: [HAT_P..][epoch:  0, iter:   7,000, lr:(4.859e-05,1.215e-05,)] [eta: 4 days, 8:07:03, time (data): 6.452 (0.003)] l_pix: 1.0588e-02 
2024-04-22 04:56:13,975 INFO: [HAT_P..][epoch:  0, iter:   7,100, lr:(4.855e-05,1.214e-05,)] [eta: 4 days, 7:56:08, time (data): 6.451 (0.003)] l_pix: 1.2491e-02 
2024-04-22 05:06:59,167 INFO: [HAT_P..][epoch:  0, iter:   7,200, lr:(4.850e-05,1.213e-05,)] [eta: 4 days, 7:45:13, time (data): 6.451 (0.003)] l_pix: 1.0829e-02 
2024-04-22 05:17:44,359 INFO: [HAT_P..][epoch:  0, iter:   7,300, lr:(4.846e-05,1.212e-05,)] [eta: 4 days, 7:34:19, time (data): 6.452 (0.003)] l_pix: 1.1897e-02 
2024-04-22 05:28:29,546 INFO: [HAT_P..][epoch:  0, iter:   7,400, lr:(4.842e-05,1.211e-05,)] [eta: 4 days, 7:23:24, time (data): 6.452 (0.003)] l_pix: 1.1879e-02 
2024-04-22 05:39:14,737 INFO: [HAT_P..][epoch:  0, iter:   7,500, lr:(4.838e-05,1.210e-05,)] [eta: 4 days, 7:12:31, time (data): 6.451 (0.003)] l_pix: 5.5885e-03 
2024-04-22 05:49:59,999 INFO: [HAT_P..][epoch:  0, iter:   7,600, lr:(4.834e-05,1.209e-05,)] [eta: 4 days, 7:01:37, time (data): 6.452 (0.003)] l_pix: 8.3701e-03 
2024-04-22 06:00:45,184 INFO: [HAT_P..][epoch:  0, iter:   7,700, lr:(4.829e-05,1.208e-05,)] [eta: 4 days, 6:50:44, time (data): 6.452 (0.003)] l_pix: 7.4705e-03 
2024-04-22 06:11:30,348 INFO: [HAT_P..][epoch:  0, iter:   7,800, lr:(4.825e-05,1.206e-05,)] [eta: 4 days, 6:39:50, time (data): 6.452 (0.003)] l_pix: 8.4541e-03 
2024-04-22 06:22:15,547 INFO: [HAT_P..][epoch:  0, iter:   7,900, lr:(4.820e-05,1.205e-05,)] [eta: 4 days, 6:28:57, time (data): 6.452 (0.003)] l_pix: 1.0103e-02 
2024-04-22 06:33:00,742 INFO: [HAT_P..][epoch:  0, iter:   8,000, lr:(4.816e-05,1.204e-05,)] [eta: 4 days, 6:18:04, time (data): 6.452 (0.003)] l_pix: 1.3077e-02 
2024-04-22 06:33:00,742 INFO: Saving models and training states.
2024-04-22 06:43:46,037 INFO: [HAT_P..][epoch:  0, iter:   8,100, lr:(4.811e-05,1.203e-05,)] [eta: 4 days, 6:07:13, time (data): 6.452 (0.003)] l_pix: 9.9966e-03 
2024-04-22 06:54:31,212 INFO: [HAT_P..][epoch:  0, iter:   8,200, lr:(4.807e-05,1.202e-05,)] [eta: 4 days, 5:56:20, time (data): 6.452 (0.003)] l_pix: 1.0328e-02 
2024-04-22 07:05:16,426 INFO: [HAT_P..][epoch:  0, iter:   8,300, lr:(4.802e-05,1.201e-05,)] [eta: 4 days, 5:45:28, time (data): 6.452 (0.003)] l_pix: 9.9090e-03 
2024-04-22 07:16:01,615 INFO: [HAT_P..][epoch:  0, iter:   8,400, lr:(4.797e-05,1.200e-05,)] [eta: 4 days, 5:34:36, time (data): 6.452 (0.003)] l_pix: 1.8396e-02 
2024-04-22 07:26:46,802 INFO: [HAT_P..][epoch:  0, iter:   8,500, lr:(4.792e-05,1.198e-05,)] [eta: 4 days, 5:23:44, time (data): 6.452 (0.003)] l_pix: 4.4575e-03 
2024-04-22 07:37:31,934 INFO: [HAT_P..][epoch:  0, iter:   8,600, lr:(4.788e-05,1.197e-05,)] [eta: 4 days, 5:12:51, time (data): 6.451 (0.003)] l_pix: 1.3164e-02 
2024-04-22 07:48:17,279 INFO: [HAT_P..][epoch:  0, iter:   8,700, lr:(4.783e-05,1.196e-05,)] [eta: 4 days, 5:02:01, time (data): 6.452 (0.003)] l_pix: 1.5800e-02 
2024-04-22 07:59:02,472 INFO: [HAT_P..][epoch:  0, iter:   8,800, lr:(4.778e-05,1.195e-05,)] [eta: 4 days, 4:51:09, time (data): 6.452 (0.003)] l_pix: 1.3819e-02 
2024-04-22 08:09:47,751 INFO: [HAT_P..][epoch:  0, iter:   8,900, lr:(4.773e-05,1.194e-05,)] [eta: 4 days, 4:40:18, time (data): 6.453 (0.003)] l_pix: 9.7420e-03 
2024-04-22 08:20:32,967 INFO: [HAT_P..][epoch:  0, iter:   9,000, lr:(4.768e-05,1.192e-05,)] [eta: 4 days, 4:29:27, time (data): 6.453 (0.003)] l_pix: 9.9271e-03 
2024-04-22 08:31:18,059 INFO: [HAT_P..][epoch:  0, iter:   9,100, lr:(4.763e-05,1.191e-05,)] [eta: 4 days, 4:18:35, time (data): 6.451 (0.003)] l_pix: 7.1485e-03 
2024-04-22 08:42:03,260 INFO: [HAT_P..][epoch:  0, iter:   9,200, lr:(4.757e-05,1.190e-05,)] [eta: 4 days, 4:07:44, time (data): 6.452 (0.003)] l_pix: 5.7768e-03 
2024-04-22 08:52:48,475 INFO: [HAT_P..][epoch:  0, iter:   9,300, lr:(4.752e-05,1.188e-05,)] [eta: 4 days, 3:56:54, time (data): 6.452 (0.003)] l_pix: 2.3163e-02 
2024-04-22 09:03:33,652 INFO: [HAT_P..][epoch:  0, iter:   9,400, lr:(4.747e-05,1.187e-05,)] [eta: 4 days, 3:46:03, time (data): 6.452 (0.003)] l_pix: 4.2129e-03 
2024-04-22 09:14:18,903 INFO: [HAT_P..][epoch:  0, iter:   9,500, lr:(4.742e-05,1.186e-05,)] [eta: 4 days, 3:35:12, time (data): 6.453 (0.003)] l_pix: 5.9523e-03 
2024-04-22 09:25:04,101 INFO: [HAT_P..][epoch:  0, iter:   9,600, lr:(4.736e-05,1.184e-05,)] [eta: 4 days, 3:24:22, time (data): 6.452 (0.003)] l_pix: 8.7220e-03 
2024-04-22 09:35:49,233 INFO: [HAT_P..][epoch:  0, iter:   9,700, lr:(4.731e-05,1.183e-05,)] [eta: 4 days, 3:13:31, time (data): 6.451 (0.003)] l_pix: 7.3137e-03 
2024-04-22 09:46:34,411 INFO: [HAT_P..][epoch:  0, iter:   9,800, lr:(4.725e-05,1.182e-05,)] [eta: 4 days, 3:02:41, time (data): 6.452 (0.003)] l_pix: 3.8186e-03 
2024-04-22 09:57:19,571 INFO: [HAT_P..][epoch:  0, iter:   9,900, lr:(4.720e-05,1.180e-05,)] [eta: 4 days, 2:51:50, time (data): 6.452 (0.003)] l_pix: 2.5321e-02 
2024-04-22 10:08:04,708 INFO: [HAT_P..][epoch:  0, iter:  10,000, lr:(4.714e-05,1.179e-05,)] [eta: 4 days, 2:41:00, time (data): 6.452 (0.003)] l_pix: 5.9653e-03 
2024-04-22 10:08:04,708 INFO: Saving models and training states.
2024-04-22 10:09:01,275 INFO: Validation Vid4
	 # psnr: 26.3626	 # calendar: 23.0986	 # city: 27.1367	 # foliage: 25.5967	 # walk: 29.6185
	    Best: 26.4002 @ 5000 iter

2024-04-22 10:19:46,328 INFO: [HAT_P..][epoch:  0, iter:  10,100, lr:(4.709e-05,1.178e-05,)] [eta: 4 days, 2:35:17, time (data): 6.452 (0.003)] l_pix: 1.6861e-02 
2024-04-22 10:30:31,451 INFO: [HAT_P..][epoch:  0, iter:  10,200, lr:(4.703e-05,1.176e-05,)] [eta: 4 days, 2:24:23, time (data): 6.451 (0.003)] l_pix: 1.4992e-02 
2024-04-22 10:41:16,610 INFO: [HAT_P..][epoch:  0, iter:  10,300, lr:(4.697e-05,1.175e-05,)] [eta: 4 days, 2:13:29, time (data): 6.452 (0.003)] l_pix: 1.3807e-02 
2024-04-22 10:52:01,663 INFO: [HAT_P..][epoch:  0, iter:  10,400, lr:(4.691e-05,1.173e-05,)] [eta: 4 days, 2:02:36, time (data): 6.451 (0.003)] l_pix: 1.4437e-02 
2024-04-22 11:02:46,361 INFO: [HAT_P..][epoch:  0, iter:  10,500, lr:(4.686e-05,1.172e-05,)] [eta: 4 days, 1:51:40, time (data): 6.446 (0.003)] l_pix: 4.0971e-03 
2024-04-22 11:13:30,804 INFO: [HAT_P..][epoch:  0, iter:  10,600, lr:(4.680e-05,1.170e-05,)] [eta: 4 days, 1:40:43, time (data): 6.445 (0.003)] l_pix: 5.7632e-03 
2024-04-22 11:24:15,214 INFO: [HAT_P..][epoch:  0, iter:  10,700, lr:(4.674e-05,1.169e-05,)] [eta: 4 days, 1:29:47, time (data): 6.444 (0.003)] l_pix: 1.8992e-02 
2024-04-22 11:34:59,690 INFO: [HAT_P..][epoch:  0, iter:  10,800, lr:(4.668e-05,1.167e-05,)] [eta: 4 days, 1:18:51, time (data): 6.445 (0.003)] l_pix: 8.9366e-03 
2024-04-22 11:45:44,139 INFO: [HAT_P..][epoch:  0, iter:  10,900, lr:(4.662e-05,1.166e-05,)] [eta: 4 days, 1:07:55, time (data): 6.444 (0.003)] l_pix: 8.9181e-03 
2024-04-22 11:56:28,555 INFO: [HAT_P..][epoch:  0, iter:  11,000, lr:(4.656e-05,1.164e-05,)] [eta: 4 days, 0:56:59, time (data): 6.444 (0.003)] l_pix: 1.5805e-02 
2024-04-22 12:07:12,994 INFO: [HAT_P..][epoch:  0, iter:  11,100, lr:(4.650e-05,1.163e-05,)] [eta: 4 days, 0:46:03, time (data): 6.444 (0.003)] l_pix: 1.0807e-02 
2024-04-22 12:17:57,445 INFO: [HAT_P..][epoch:  0, iter:  11,200, lr:(4.643e-05,1.161e-05,)] [eta: 4 days, 0:35:08, time (data): 6.444 (0.003)] l_pix: 1.7711e-02 
2024-04-22 12:28:41,860 INFO: [HAT_P..][epoch:  0, iter:  11,300, lr:(4.637e-05,1.160e-05,)] [eta: 4 days, 0:24:13, time (data): 6.444 (0.003)] l_pix: 6.0950e-03 
2024-04-22 12:39:26,252 INFO: [HAT_P..][epoch:  0, iter:  11,400, lr:(4.631e-05,1.158e-05,)] [eta: 4 days, 0:13:17, time (data): 6.444 (0.003)] l_pix: 1.6779e-02 
2024-04-22 12:50:10,633 INFO: [HAT_P..][epoch:  0, iter:  11,500, lr:(4.624e-05,1.157e-05,)] [eta: 4 days, 0:02:22, time (data): 6.444 (0.003)] l_pix: 1.6096e-02 
2024-04-22 13:00:55,025 INFO: [HAT_P..][epoch:  0, iter:  11,600, lr:(4.618e-05,1.155e-05,)] [eta: 3 days, 23:51:27, time (data): 6.444 (0.003)] l_pix: 1.9120e-02 
2024-04-22 13:11:38,930 INFO: [HAT_P..][epoch:  0, iter:  11,700, lr:(4.612e-05,1.153e-05,)] [eta: 3 days, 23:40:30, time (data): 6.443 (0.003)] l_pix: 2.1556e-02 
2024-04-22 13:22:20,933 INFO: [HAT_P..][epoch:  0, iter:  11,800, lr:(4.605e-05,1.152e-05,)] [eta: 3 days, 23:29:25, time (data): 6.427 (0.003)] l_pix: 1.7799e-02 
2024-04-22 13:33:02,417 INFO: [HAT_P..][epoch:  0, iter:  11,900, lr:(4.599e-05,1.150e-05,)] [eta: 3 days, 23:18:18, time (data): 6.415 (0.003)] l_pix: 6.6472e-03 
2024-04-22 13:43:43,861 INFO: [HAT_P..][epoch:  0, iter:  12,000, lr:(4.592e-05,1.149e-05,)] [eta: 3 days, 23:07:11, time (data): 6.415 (0.003)] l_pix: 7.5857e-03 
2024-04-22 13:43:43,861 INFO: Saving models and training states.
2024-04-22 13:54:24,220 INFO: [HAT_P..][epoch:  0, iter:  12,100, lr:(4.585e-05,1.147e-05,)] [eta: 3 days, 22:56:00, time (data): 6.402 (0.003)] l_pix: 1.6968e-02 
2024-04-22 14:05:04,409 INFO: [HAT_P..][epoch:  0, iter:  12,200, lr:(4.579e-05,1.145e-05,)] [eta: 3 days, 22:44:48, time (data): 6.402 (0.003)] l_pix: 1.4888e-02 
2024-04-22 14:15:44,590 INFO: [HAT_P..][epoch:  0, iter:  12,300, lr:(4.572e-05,1.144e-05,)] [eta: 3 days, 22:33:37, time (data): 6.402 (0.003)] l_pix: 2.3266e-02 
2024-04-22 14:26:24,879 INFO: [HAT_P..][epoch:  0, iter:  12,400, lr:(4.565e-05,1.142e-05,)] [eta: 3 days, 22:22:27, time (data): 6.403 (0.003)] l_pix: 1.6446e-02 
2024-04-22 14:37:05,051 INFO: [HAT_P..][epoch:  0, iter:  12,500, lr:(4.558e-05,1.140e-05,)] [eta: 3 days, 22:11:17, time (data): 6.402 (0.003)] l_pix: 5.1186e-03 
2024-04-22 14:47:45,255 INFO: [HAT_P..][epoch:  0, iter:  12,600, lr:(4.552e-05,1.139e-05,)] [eta: 3 days, 22:00:08, time (data): 6.402 (0.003)] l_pix: 1.5720e-02 
2024-04-22 14:58:25,496 INFO: [HAT_P..][epoch:  0, iter:  12,700, lr:(4.545e-05,1.137e-05,)] [eta: 3 days, 21:48:59, time (data): 6.402 (0.003)] l_pix: 6.7109e-03 
2024-04-22 15:09:05,688 INFO: [HAT_P..][epoch:  0, iter:  12,800, lr:(4.538e-05,1.135e-05,)] [eta: 3 days, 21:37:50, time (data): 6.402 (0.003)] l_pix: 1.3032e-02 
2024-04-22 15:19:45,969 INFO: [HAT_P..][epoch:  0, iter:  12,900, lr:(4.531e-05,1.133e-05,)] [eta: 3 days, 21:26:43, time (data): 6.404 (0.003)] l_pix: 1.6214e-02 
2024-04-22 15:30:26,220 INFO: [HAT_P..][epoch:  0, iter:  13,000, lr:(4.524e-05,1.132e-05,)] [eta: 3 days, 21:15:35, time (data): 6.403 (0.003)] l_pix: 1.5074e-02 
2024-04-22 15:41:06,445 INFO: [HAT_P..][epoch:  0, iter:  13,100, lr:(4.516e-05,1.130e-05,)] [eta: 3 days, 21:04:28, time (data): 6.403 (0.002)] l_pix: 1.2779e-02 
2024-04-22 15:51:48,797 INFO: [HAT_P..][epoch:  0, iter:  13,200, lr:(4.509e-05,1.128e-05,)] [eta: 3 days, 20:53:29, time (data): 6.418 (0.003)] l_pix: 1.5053e-02 
2024-04-22 16:02:29,547 INFO: [HAT_P..][epoch:  0, iter:  13,300, lr:(4.502e-05,1.126e-05,)] [eta: 3 days, 20:42:25, time (data): 6.402 (0.003)] l_pix: 1.9312e-02 
2024-04-22 16:13:14,427 INFO: [HAT_P..][epoch:  0, iter:  13,400, lr:(4.495e-05,1.124e-05,)] [eta: 3 days, 20:31:37, time (data): 6.437 (0.003)] l_pix: 1.9520e-02 
2024-04-22 16:24:03,733 INFO: [HAT_P..][epoch:  0, iter:  13,500, lr:(4.488e-05,1.123e-05,)] [eta: 3 days, 20:21:06, time (data): 6.540 (0.003)] l_pix: 5.1715e-03 
2024-04-22 16:34:48,324 INFO: [HAT_P..][epoch:  0, iter:  13,600, lr:(4.480e-05,1.121e-05,)] [eta: 3 days, 20:10:16, time (data): 6.469 (0.003)] l_pix: 1.1994e-02 
2024-04-22 16:45:29,721 INFO: [HAT_P..][epoch:  0, iter:  13,700, lr:(4.473e-05,1.119e-05,)] [eta: 3 days, 19:59:15, time (data): 6.401 (0.002)] l_pix: 7.1332e-03 
2024-04-22 16:56:09,860 INFO: [HAT_P..][epoch:  0, iter:  13,800, lr:(4.465e-05,1.117e-05,)] [eta: 3 days, 19:48:10, time (data): 6.401 (0.003)] l_pix: 1.4158e-02 
2024-04-22 17:06:49,921 INFO: [HAT_P..][epoch:  0, iter:  13,900, lr:(4.458e-05,1.115e-05,)] [eta: 3 days, 19:37:04, time (data): 6.401 (0.003)] l_pix: 1.5432e-02 
2024-04-22 17:17:30,055 INFO: [HAT_P..][epoch:  0, iter:  14,000, lr:(4.450e-05,1.113e-05,)] [eta: 3 days, 19:25:59, time (data): 6.401 (0.003)] l_pix: 1.0296e-02 
2024-04-22 17:17:30,055 INFO: Saving models and training states.
2024-04-22 17:28:10,258 INFO: [HAT_P..][epoch:  0, iter:  14,100, lr:(4.443e-05,1.112e-05,)] [eta: 3 days, 19:14:55, time (data): 6.400 (0.002)] l_pix: 1.3122e-02 
2024-04-22 17:38:50,325 INFO: [HAT_P..][epoch:  0, iter:  14,200, lr:(4.435e-05,1.110e-05,)] [eta: 3 days, 19:03:51, time (data): 6.401 (0.003)] l_pix: 1.8680e-02 
2024-04-22 17:49:33,412 INFO: [HAT_P..][epoch:  0, iter:  14,300, lr:(4.428e-05,1.108e-05,)] [eta: 3 days, 18:52:57, time (data): 6.400 (0.003)] l_pix: 1.3118e-02 
2024-04-22 18:00:13,462 INFO: [HAT_P..][epoch:  0, iter:  14,400, lr:(4.420e-05,1.106e-05,)] [eta: 3 days, 18:41:53, time (data): 6.400 (0.003)] l_pix: 1.3552e-02 
2024-04-22 18:10:54,862 INFO: [HAT_P..][epoch:  0, iter:  14,500, lr:(4.412e-05,1.104e-05,)] [eta: 3 days, 18:30:54, time (data): 6.417 (0.003)] l_pix: 2.7049e-03 
2024-04-22 18:21:45,455 INFO: [HAT_P..][epoch:  0, iter:  14,600, lr:(4.404e-05,1.102e-05,)] [eta: 3 days, 18:20:28, time (data): 6.487 (0.003)] l_pix: 1.6375e-02 
2024-04-22 18:32:30,067 INFO: [HAT_P..][epoch:  0, iter:  14,700, lr:(4.396e-05,1.100e-05,)] [eta: 3 days, 18:09:40, time (data): 6.401 (0.003)] l_pix: 7.6551e-03 
2024-04-22 18:43:10,210 INFO: [HAT_P..][epoch:  0, iter:  14,800, lr:(4.389e-05,1.098e-05,)] [eta: 3 days, 17:58:37, time (data): 6.401 (0.003)] l_pix: 3.7477e-03 
2024-04-22 18:53:50,244 INFO: [HAT_P..][epoch:  0, iter:  14,900, lr:(4.381e-05,1.096e-05,)] [eta: 3 days, 17:47:34, time (data): 6.400 (0.003)] l_pix: 6.5819e-03 
2024-04-22 19:04:30,246 INFO: [HAT_P..][epoch:  0, iter:  15,000, lr:(4.373e-05,1.094e-05,)] [eta: 3 days, 17:36:32, time (data): 6.400 (0.003)] l_pix: 1.3271e-02 
2024-04-22 19:05:26,049 INFO: Validation Vid4
	 # psnr: 26.4520	 # calendar: 23.1510	 # city: 27.2163	 # foliage: 25.7303	 # walk: 29.7106
	    Best: 26.4520 @ 15000 iter

2024-04-22 19:16:06,106 INFO: [HAT_P..][epoch:  0, iter:  15,100, lr:(4.365e-05,1.092e-05,)] [eta: 3 days, 17:28:34, time (data): 6.402 (0.002)] l_pix: 7.7464e-03 
2024-04-22 19:26:46,132 INFO: [HAT_P..][epoch:  0, iter:  15,200, lr:(4.357e-05,1.090e-05,)] [eta: 3 days, 17:17:30, time (data): 6.401 (0.003)] l_pix: 9.9402e-03 
2024-04-22 19:37:26,282 INFO: [HAT_P..][epoch:  0, iter:  15,300, lr:(4.348e-05,1.088e-05,)] [eta: 3 days, 17:06:27, time (data): 6.402 (0.002)] l_pix: 2.0326e-02 
2024-04-22 19:48:06,372 INFO: [HAT_P..][epoch:  0, iter:  15,400, lr:(4.340e-05,1.086e-05,)] [eta: 3 days, 16:55:25, time (data): 6.401 (0.002)] l_pix: 5.0243e-03 
2024-04-22 19:58:46,804 INFO: [HAT_P..][epoch:  0, iter:  15,500, lr:(4.332e-05,1.084e-05,)] [eta: 3 days, 16:44:23, time (data): 6.417 (0.002)] l_pix: 5.9932e-03 
2024-04-22 20:09:27,066 INFO: [HAT_P..][epoch:  0, iter:  15,600, lr:(4.324e-05,1.082e-05,)] [eta: 3 days, 16:33:22, time (data): 6.405 (0.002)] l_pix: 1.7169e-02 
2024-04-22 20:20:12,894 INFO: [HAT_P..][epoch:  0, iter:  15,700, lr:(4.316e-05,1.080e-05,)] [eta: 3 days, 16:22:38, time (data): 6.460 (0.003)] l_pix: 1.3430e-02 
2024-04-22 20:31:06,994 INFO: [HAT_P..][epoch:  0, iter:  15,800, lr:(4.307e-05,1.078e-05,)] [eta: 3 days, 16:12:19, time (data): 6.526 (0.003)] l_pix: 1.2219e-02 
2024-04-22 20:41:47,206 INFO: [HAT_P..][epoch:  0, iter:  15,900, lr:(4.299e-05,1.076e-05,)] [eta: 3 days, 16:01:18, time (data): 6.403 (0.003)] l_pix: 8.0727e-03 
2024-04-22 20:52:37,876 INFO: [HAT_P..][epoch:  0, iter:  16,000, lr:(4.291e-05,1.074e-05,)] [eta: 3 days, 15:50:49, time (data): 6.489 (0.003)] l_pix: 8.6991e-03 
2024-04-22 20:52:37,877 INFO: Saving models and training states.
2024-04-22 21:03:28,097 INFO: [HAT_P..][epoch:  0, iter:  16,100, lr:(4.282e-05,1.072e-05,)] [eta: 3 days, 15:40:18, time (data): 6.488 (0.003)] l_pix: 1.0352e-02 
2024-04-22 21:14:12,594 INFO: [HAT_P..][epoch:  0, iter:  16,200, lr:(4.274e-05,1.069e-05,)] [eta: 3 days, 15:29:30, time (data): 6.452 (0.003)] l_pix: 1.9056e-02 
2024-04-22 21:24:55,025 INFO: [HAT_P..][epoch:  0, iter:  16,300, lr:(4.265e-05,1.067e-05,)] [eta: 3 days, 15:18:35, time (data): 6.422 (0.003)] l_pix: 7.1804e-03 
2024-04-22 21:35:37,190 INFO: [HAT_P..][epoch:  0, iter:  16,400, lr:(4.256e-05,1.065e-05,)] [eta: 3 days, 15:07:40, time (data): 6.422 (0.003)] l_pix: 1.1426e-02 
2024-04-22 21:46:19,306 INFO: [HAT_P..][epoch:  0, iter:  16,500, lr:(4.248e-05,1.063e-05,)] [eta: 3 days, 14:56:45, time (data): 6.422 (0.003)] l_pix: 8.8874e-03 
2024-04-22 21:57:01,411 INFO: [HAT_P..][epoch:  0, iter:  16,600, lr:(4.239e-05,1.061e-05,)] [eta: 3 days, 14:45:50, time (data): 6.421 (0.003)] l_pix: 1.0923e-02 
2024-04-22 22:07:43,550 INFO: [HAT_P..][epoch:  0, iter:  16,700, lr:(4.231e-05,1.059e-05,)] [eta: 3 days, 14:34:55, time (data): 6.422 (0.003)] l_pix: 5.2891e-03 
2024-04-22 22:18:25,687 INFO: [HAT_P..][epoch:  0, iter:  16,800, lr:(4.222e-05,1.057e-05,)] [eta: 3 days, 14:24:01, time (data): 6.421 (0.003)] l_pix: 2.2140e-02 
2024-04-22 22:29:07,811 INFO: [HAT_P..][epoch:  0, iter:  16,900, lr:(4.213e-05,1.054e-05,)] [eta: 3 days, 14:13:06, time (data): 6.422 (0.003)] l_pix: 4.5847e-03 
2024-04-22 22:39:49,912 INFO: [HAT_P..][epoch:  0, iter:  17,000, lr:(4.204e-05,1.052e-05,)] [eta: 3 days, 14:02:12, time (data): 6.421 (0.003)] l_pix: 1.2502e-02 
2024-04-22 22:50:32,058 INFO: [HAT_P..][epoch:  0, iter:  17,100, lr:(4.195e-05,1.050e-05,)] [eta: 3 days, 13:51:18, time (data): 6.421 (0.002)] l_pix: 1.0200e-02 
2024-04-22 23:01:14,277 INFO: [HAT_P..][epoch:  0, iter:  17,200, lr:(4.186e-05,1.048e-05,)] [eta: 3 days, 13:40:24, time (data): 6.422 (0.003)] l_pix: 1.1992e-02 
2024-04-22 23:11:55,380 INFO: [HAT_P..][epoch:  0, iter:  17,300, lr:(4.178e-05,1.046e-05,)] [eta: 3 days, 13:29:27, time (data): 6.402 (0.003)] l_pix: 7.8885e-03 
2024-04-22 23:22:35,642 INFO: [HAT_P..][epoch:  0, iter:  17,400, lr:(4.169e-05,1.043e-05,)] [eta: 3 days, 13:18:29, time (data): 6.403 (0.003)] l_pix: 6.9438e-03 
2024-04-22 23:33:15,935 INFO: [HAT_P..][epoch:  0, iter:  17,500, lr:(4.160e-05,1.041e-05,)] [eta: 3 days, 13:07:30, time (data): 6.412 (0.003)] l_pix: 1.0253e-02 
2024-04-22 23:43:56,141 INFO: [HAT_P..][epoch:  0, iter:  17,600, lr:(4.151e-05,1.039e-05,)] [eta: 3 days, 12:56:32, time (data): 6.403 (0.003)] l_pix: 1.3211e-02 
2024-04-22 23:54:36,455 INFO: [HAT_P..][epoch:  0, iter:  17,700, lr:(4.141e-05,1.037e-05,)] [eta: 3 days, 12:45:34, time (data): 6.400 (0.003)] l_pix: 1.0859e-02 
2024-04-23 00:05:16,569 INFO: [HAT_P..][epoch:  0, iter:  17,800, lr:(4.132e-05,1.034e-05,)] [eta: 3 days, 12:34:35, time (data): 6.401 (0.003)] l_pix: 9.9585e-03 
2024-04-23 00:15:56,563 INFO: [HAT_P..][epoch:  0, iter:  17,900, lr:(4.123e-05,1.032e-05,)] [eta: 3 days, 12:23:37, time (data): 6.399 (0.002)] l_pix: 6.8063e-03 
2024-04-23 00:26:36,592 INFO: [HAT_P..][epoch:  0, iter:  18,000, lr:(4.114e-05,1.030e-05,)] [eta: 3 days, 12:12:38, time (data): 6.400 (0.002)] l_pix: 1.2014e-02 
2024-04-23 00:26:36,592 INFO: Saving models and training states.
2024-04-23 00:37:16,800 INFO: [HAT_P..][epoch:  0, iter:  18,100, lr:(4.105e-05,1.028e-05,)] [eta: 3 days, 12:01:41, time (data): 6.402 (0.002)] l_pix: 5.6225e-03 
2024-04-23 00:47:56,911 INFO: [HAT_P..][epoch:  0, iter:  18,200, lr:(4.095e-05,1.025e-05,)] [eta: 3 days, 11:50:43, time (data): 6.401 (0.002)] l_pix: 6.3283e-03 
2024-04-23 00:58:37,013 INFO: [HAT_P..][epoch:  0, iter:  18,300, lr:(4.086e-05,1.023e-05,)] [eta: 3 days, 11:39:46, time (data): 6.401 (0.003)] l_pix: 6.2742e-03 
2024-04-23 01:09:17,091 INFO: [HAT_P..][epoch:  0, iter:  18,400, lr:(4.077e-05,1.021e-05,)] [eta: 3 days, 11:28:49, time (data): 6.401 (0.003)] l_pix: 1.4607e-02 
2024-04-23 01:19:57,226 INFO: [HAT_P..][epoch:  0, iter:  18,500, lr:(4.067e-05,1.018e-05,)] [eta: 3 days, 11:17:52, time (data): 6.402 (0.003)] l_pix: 8.0654e-03 
2024-04-23 01:30:37,349 INFO: [HAT_P..][epoch:  0, iter:  18,600, lr:(4.058e-05,1.016e-05,)] [eta: 3 days, 11:06:55, time (data): 6.401 (0.003)] l_pix: 8.6339e-03 
2024-04-23 01:41:17,430 INFO: [HAT_P..][epoch:  0, iter:  18,700, lr:(4.049e-05,1.014e-05,)] [eta: 3 days, 10:55:58, time (data): 6.401 (0.003)] l_pix: 1.0537e-02 
2024-04-23 01:51:57,440 INFO: [HAT_P..][epoch:  0, iter:  18,800, lr:(4.039e-05,1.011e-05,)] [eta: 3 days, 10:45:01, time (data): 6.400 (0.003)] l_pix: 5.1317e-03 
2024-04-23 02:02:37,478 INFO: [HAT_P..][epoch:  0, iter:  18,900, lr:(4.030e-05,1.009e-05,)] [eta: 3 days, 10:34:05, time (data): 6.401 (0.002)] l_pix: 1.3165e-02 
2024-04-23 02:13:17,510 INFO: [HAT_P..][epoch:  0, iter:  19,000, lr:(4.020e-05,1.006e-05,)] [eta: 3 days, 10:23:08, time (data): 6.400 (0.003)] l_pix: 1.0280e-02 
2024-04-23 02:23:57,591 INFO: [HAT_P..][epoch:  0, iter:  19,100, lr:(4.010e-05,1.004e-05,)] [eta: 3 days, 10:12:12, time (data): 6.400 (0.002)] l_pix: 1.0454e-02 
2024-04-23 02:34:37,784 INFO: [HAT_P..][epoch:  0, iter:  19,200, lr:(4.001e-05,1.002e-05,)] [eta: 3 days, 10:01:17, time (data): 6.402 (0.002)] l_pix: 1.2371e-02 
2024-04-23 02:45:17,822 INFO: [HAT_P..][epoch:  0, iter:  19,300, lr:(3.991e-05,9.993e-06,)] [eta: 3 days, 9:50:21, time (data): 6.399 (0.002)] l_pix: 6.8204e-03 
2024-04-23 02:55:57,827 INFO: [HAT_P..][epoch:  0, iter:  19,400, lr:(3.981e-05,9.969e-06,)] [eta: 3 days, 9:39:25, time (data): 6.400 (0.002)] l_pix: 1.6769e-02 
2024-04-23 03:06:37,836 INFO: [HAT_P..][epoch:  0, iter:  19,500, lr:(3.972e-05,9.945e-06,)] [eta: 3 days, 9:28:30, time (data): 6.399 (0.002)] l_pix: 1.0931e-02 
2024-04-23 03:17:17,871 INFO: [HAT_P..][epoch:  0, iter:  19,600, lr:(3.962e-05,9.920e-06,)] [eta: 3 days, 9:17:34, time (data): 6.400 (0.002)] l_pix: 6.4678e-03 
2024-04-23 03:27:57,911 INFO: [HAT_P..][epoch:  0, iter:  19,700, lr:(3.952e-05,9.896e-06,)] [eta: 3 days, 9:06:39, time (data): 6.399 (0.002)] l_pix: 6.3931e-03 
2024-04-23 03:38:38,004 INFO: [HAT_P..][epoch:  0, iter:  19,800, lr:(3.942e-05,9.871e-06,)] [eta: 3 days, 8:55:44, time (data): 6.401 (0.003)] l_pix: 1.3904e-02 
2024-04-23 03:49:18,116 INFO: [HAT_P..][epoch:  0, iter:  19,900, lr:(3.932e-05,9.847e-06,)] [eta: 3 days, 8:44:50, time (data): 6.402 (0.003)] l_pix: 1.2378e-02 
2024-04-23 03:59:58,149 INFO: [HAT_P..][epoch:  0, iter:  20,000, lr:(3.922e-05,9.822e-06,)] [eta: 3 days, 8:33:55, time (data): 6.400 (0.003)] l_pix: 2.0495e-02 
2024-04-23 03:59:58,149 INFO: Saving models and training states.
2024-04-23 04:00:54,198 INFO: Validation Vid4
	 # psnr: 26.4681	 # calendar: 23.1887	 # city: 27.2571	 # foliage: 25.6787	 # walk: 29.7478
	    Best: 26.4681 @ 20000 iter

2024-04-23 04:11:34,239 INFO: [HAT_P..][epoch:  0, iter:  20,100, lr:(3.912e-05,9.798e-06,)] [eta: 3 days, 8:25:05, time (data): 6.400 (0.003)] l_pix: 1.4001e-02 
2024-04-23 04:22:14,259 INFO: [HAT_P..][epoch:  0, iter:  20,200, lr:(3.903e-05,9.773e-06,)] [eta: 3 days, 8:14:10, time (data): 6.400 (0.003)] l_pix: 2.1440e-02 
2024-04-23 04:32:54,267 INFO: [HAT_P..][epoch:  0, iter:  20,300, lr:(3.893e-05,9.748e-06,)] [eta: 3 days, 8:03:15, time (data): 6.400 (0.003)] l_pix: 5.5311e-03 
2024-04-23 04:43:34,217 INFO: [HAT_P..][epoch:  0, iter:  20,400, lr:(3.882e-05,9.723e-06,)] [eta: 3 days, 7:52:20, time (data): 6.399 (0.003)] l_pix: 6.4842e-03 
2024-04-23 04:54:14,171 INFO: [HAT_P..][epoch:  0, iter:  20,500, lr:(3.872e-05,9.698e-06,)] [eta: 3 days, 7:41:24, time (data): 6.400 (0.003)] l_pix: 1.7579e-02 
2024-04-23 05:04:54,197 INFO: [HAT_P..][epoch:  0, iter:  20,600, lr:(3.862e-05,9.673e-06,)] [eta: 3 days, 7:30:30, time (data): 6.400 (0.003)] l_pix: 1.4766e-02 
2024-04-23 05:15:34,260 INFO: [HAT_P..][epoch:  0, iter:  20,700, lr:(3.852e-05,9.648e-06,)] [eta: 3 days, 7:19:35, time (data): 6.400 (0.003)] l_pix: 7.0256e-03 
2024-04-23 05:26:14,380 INFO: [HAT_P..][epoch:  0, iter:  20,800, lr:(3.842e-05,9.622e-06,)] [eta: 3 days, 7:08:41, time (data): 6.401 (0.003)] l_pix: 6.5014e-03 
2024-04-23 05:36:54,526 INFO: [HAT_P..][epoch:  0, iter:  20,900, lr:(3.832e-05,9.597e-06,)] [eta: 3 days, 6:57:47, time (data): 6.401 (0.003)] l_pix: 1.3325e-02 
2024-04-23 05:47:35,754 INFO: [HAT_P..][epoch:  0, iter:  21,000, lr:(3.822e-05,9.572e-06,)] [eta: 3 days, 6:46:55, time (data): 6.413 (0.003)] l_pix: 2.0913e-02 
2024-04-23 05:58:16,294 INFO: [HAT_P..][epoch:  0, iter:  21,100, lr:(3.811e-05,9.546e-06,)] [eta: 3 days, 6:36:02, time (data): 6.409 (0.003)] l_pix: 8.6151e-03 
2024-04-23 06:08:56,752 INFO: [HAT_P..][epoch:  0, iter:  21,200, lr:(3.801e-05,9.521e-06,)] [eta: 3 days, 6:25:09, time (data): 6.404 (0.003)] l_pix: 1.8434e-02 
2024-04-23 06:19:37,322 INFO: [HAT_P..][epoch:  0, iter:  21,300, lr:(3.791e-05,9.495e-06,)] [eta: 3 days, 6:14:16, time (data): 6.405 (0.003)] l_pix: 8.3591e-03 
2024-04-23 06:30:17,963 INFO: [HAT_P..][epoch:  0, iter:  21,400, lr:(3.780e-05,9.469e-06,)] [eta: 3 days, 6:03:24, time (data): 6.406 (0.003)] l_pix: 1.3954e-02 
2024-04-23 06:40:58,893 INFO: [HAT_P..][epoch:  0, iter:  21,500, lr:(3.770e-05,9.443e-06,)] [eta: 3 days, 5:52:32, time (data): 6.408 (0.003)] l_pix: 1.4340e-02 
2024-04-23 06:51:42,307 INFO: [HAT_P..][epoch:  0, iter:  21,600, lr:(3.760e-05,9.418e-06,)] [eta: 3 days, 5:41:45, time (data): 6.434 (0.003)] l_pix: 9.6890e-03 
2024-04-23 07:02:25,688 INFO: [HAT_P..][epoch:  0, iter:  21,700, lr:(3.749e-05,9.392e-06,)] [eta: 3 days, 5:30:59, time (data): 6.434 (0.003)] l_pix: 1.3168e-02 
2024-04-23 07:13:09,159 INFO: [HAT_P..][epoch:  0, iter:  21,800, lr:(3.739e-05,9.366e-06,)] [eta: 3 days, 5:20:12, time (data): 6.435 (0.003)] l_pix: 1.0461e-02 
2024-04-23 07:23:52,663 INFO: [HAT_P..][epoch:  0, iter:  21,900, lr:(3.728e-05,9.340e-06,)] [eta: 3 days, 5:09:26, time (data): 6.435 (0.003)] l_pix: 7.1693e-03 
2024-04-23 07:34:36,180 INFO: [HAT_P..][epoch:  0, iter:  22,000, lr:(3.718e-05,9.313e-06,)] [eta: 3 days, 4:58:39, time (data): 6.435 (0.003)] l_pix: 4.9474e-03 
2024-04-23 07:34:36,181 INFO: Saving models and training states.
2024-04-23 07:45:19,881 INFO: [HAT_P..][epoch:  0, iter:  22,100, lr:(3.707e-05,9.287e-06,)] [eta: 3 days, 4:47:53, time (data): 6.435 (0.003)] l_pix: 1.5951e-02 
2024-04-23 07:56:03,398 INFO: [HAT_P..][epoch:  0, iter:  22,200, lr:(3.697e-05,9.261e-06,)] [eta: 3 days, 4:37:07, time (data): 6.435 (0.003)] l_pix: 1.8476e-02 
2024-04-23 08:06:46,964 INFO: [HAT_P..][epoch:  0, iter:  22,300, lr:(3.686e-05,9.234e-06,)] [eta: 3 days, 4:26:21, time (data): 6.435 (0.003)] l_pix: 6.4303e-03 
2024-04-23 08:17:30,483 INFO: [HAT_P..][epoch:  0, iter:  22,400, lr:(3.675e-05,9.208e-06,)] [eta: 3 days, 4:15:34, time (data): 6.435 (0.003)] l_pix: 1.4801e-02 
2024-04-23 08:28:14,006 INFO: [HAT_P..][epoch:  0, iter:  22,500, lr:(3.665e-05,9.182e-06,)] [eta: 3 days, 4:04:48, time (data): 6.435 (0.003)] l_pix: 1.9202e-02 
2024-04-23 08:38:57,579 INFO: [HAT_P..][epoch:  0, iter:  22,600, lr:(3.654e-05,9.155e-06,)] [eta: 3 days, 3:54:02, time (data): 6.436 (0.003)] l_pix: 9.6018e-03 
2024-04-23 08:49:41,116 INFO: [HAT_P..][epoch:  0, iter:  22,700, lr:(3.643e-05,9.128e-06,)] [eta: 3 days, 3:43:16, time (data): 6.435 (0.003)] l_pix: 1.1465e-02 
2024-04-23 09:00:24,732 INFO: [HAT_P..][epoch:  0, iter:  22,800, lr:(3.632e-05,9.102e-06,)] [eta: 3 days, 3:32:30, time (data): 6.436 (0.003)] l_pix: 1.4607e-02 
2024-04-23 09:11:08,308 INFO: [HAT_P..][epoch:  0, iter:  22,900, lr:(3.622e-05,9.075e-06,)] [eta: 3 days, 3:21:44, time (data): 6.436 (0.003)] l_pix: 1.3606e-02 
2024-04-23 09:21:51,918 INFO: [HAT_P..][epoch:  0, iter:  23,000, lr:(3.611e-05,9.048e-06,)] [eta: 3 days, 3:10:58, time (data): 6.436 (0.003)] l_pix: 9.8035e-03 
2024-04-23 09:32:35,519 INFO: [HAT_P..][epoch:  0, iter:  23,100, lr:(3.600e-05,9.021e-06,)] [eta: 3 days, 3:00:12, time (data): 6.436 (0.003)] l_pix: 8.4100e-03 
2024-04-23 09:43:19,153 INFO: [HAT_P..][epoch:  0, iter:  23,200, lr:(3.589e-05,8.994e-06,)] [eta: 3 days, 2:49:26, time (data): 6.436 (0.003)] l_pix: 6.2385e-03 
2024-04-23 09:54:02,748 INFO: [HAT_P..][epoch:  0, iter:  23,300, lr:(3.578e-05,8.967e-06,)] [eta: 3 days, 2:38:40, time (data): 6.436 (0.003)] l_pix: 1.1230e-02 
2024-04-23 10:04:46,391 INFO: [HAT_P..][epoch:  0, iter:  23,400, lr:(3.567e-05,8.940e-06,)] [eta: 3 days, 2:27:54, time (data): 6.436 (0.003)] l_pix: 1.0243e-02 
2024-04-23 10:15:30,007 INFO: [HAT_P..][epoch:  0, iter:  23,500, lr:(3.557e-05,8.913e-06,)] [eta: 3 days, 2:17:08, time (data): 6.436 (0.003)] l_pix: 4.9456e-03 
2024-04-23 10:26:13,656 INFO: [HAT_P..][epoch:  0, iter:  23,600, lr:(3.546e-05,8.886e-06,)] [eta: 3 days, 2:06:23, time (data): 6.437 (0.002)] l_pix: 8.8395e-03 
2024-04-23 10:36:56,821 INFO: [HAT_P..][epoch:  0, iter:  23,700, lr:(3.535e-05,8.858e-06,)] [eta: 3 days, 1:55:36, time (data): 6.434 (0.002)] l_pix: 4.5068e-03 
2024-04-23 10:47:39,710 INFO: [HAT_P..][epoch:  0, iter:  23,800, lr:(3.524e-05,8.831e-06,)] [eta: 3 days, 1:44:49, time (data): 6.428 (0.003)] l_pix: 5.3423e-03 
2024-04-23 10:58:22,548 INFO: [HAT_P..][epoch:  0, iter:  23,900, lr:(3.513e-05,8.804e-06,)] [eta: 3 days, 1:34:02, time (data): 6.428 (0.003)] l_pix: 5.5943e-03 
2024-04-23 11:09:05,350 INFO: [HAT_P..][epoch:  0, iter:  24,000, lr:(3.502e-05,8.776e-06,)] [eta: 3 days, 1:23:15, time (data): 6.428 (0.003)] l_pix: 8.4458e-03 
2024-04-23 11:09:05,350 INFO: Saving models and training states.
2024-04-23 11:19:48,320 INFO: [HAT_P..][epoch:  0, iter:  24,100, lr:(3.490e-05,8.749e-06,)] [eta: 3 days, 1:12:28, time (data): 6.428 (0.003)] l_pix: 5.3673e-03 
2024-04-23 11:30:31,162 INFO: [HAT_P..][epoch:  0, iter:  24,200, lr:(3.479e-05,8.721e-06,)] [eta: 3 days, 1:01:41, time (data): 6.428 (0.003)] l_pix: 1.5924e-02 
2024-04-23 11:41:13,977 INFO: [HAT_P..][epoch:  0, iter:  24,300, lr:(3.468e-05,8.694e-06,)] [eta: 3 days, 0:50:54, time (data): 6.428 (0.003)] l_pix: 7.2601e-03 
2024-04-23 11:51:55,737 INFO: [HAT_P..][epoch:  0, iter:  24,400, lr:(3.457e-05,8.666e-06,)] [eta: 3 days, 0:40:05, time (data): 6.415 (0.003)] l_pix: 2.3945e-03 
2024-04-23 12:02:35,868 INFO: [HAT_P..][epoch:  0, iter:  24,500, lr:(3.446e-05,8.638e-06,)] [eta: 3 days, 0:29:14, time (data): 6.407 (0.003)] l_pix: 1.0177e-02 
2024-04-23 12:13:15,995 INFO: [HAT_P..][epoch:  0, iter:  24,600, lr:(3.435e-05,8.610e-06,)] [eta: 3 days, 0:18:23, time (data): 6.401 (0.003)] l_pix: 1.8971e-02 
2024-04-23 12:23:56,124 INFO: [HAT_P..][epoch:  0, iter:  24,700, lr:(3.424e-05,8.583e-06,)] [eta: 3 days, 0:07:31, time (data): 6.401 (0.003)] l_pix: 9.9599e-03 
2024-04-23 12:34:36,270 INFO: [HAT_P..][epoch:  0, iter:  24,800, lr:(3.412e-05,8.555e-06,)] [eta: 2 days, 23:56:40, time (data): 6.401 (0.003)] l_pix: 1.0490e-02 
2024-04-23 12:45:16,369 INFO: [HAT_P..][epoch:  0, iter:  24,900, lr:(3.401e-05,8.527e-06,)] [eta: 2 days, 23:45:49, time (data): 6.401 (0.003)] l_pix: 5.0616e-03 
2024-04-23 12:55:56,484 INFO: [HAT_P..][epoch:  0, iter:  25,000, lr:(3.390e-05,8.499e-06,)] [eta: 2 days, 23:34:58, time (data): 6.401 (0.003)] l_pix: 1.0041e-02 
2024-04-23 12:56:52,299 INFO: Validation Vid4
	 # psnr: 26.5002	 # calendar: 23.2211	 # city: 27.2260	 # foliage: 25.7645	 # walk: 29.7890
	    Best: 26.5002 @ 25000 iter

2024-04-23 13:07:32,406 INFO: [HAT_P..][epoch:  0, iter:  25,100, lr:(3.379e-05,8.471e-06,)] [eta: 2 days, 23:25:36, time (data): 6.401 (0.003)] l_pix: 7.4527e-03 
2024-04-23 13:18:12,528 INFO: [HAT_P..][epoch:  0, iter:  25,200, lr:(3.367e-05,8.443e-06,)] [eta: 2 days, 23:14:45, time (data): 6.401 (0.003)] l_pix: 2.6098e-02 
2024-04-23 13:28:52,652 INFO: [HAT_P..][epoch:  0, iter:  25,300, lr:(3.356e-05,8.415e-06,)] [eta: 2 days, 23:03:54, time (data): 6.401 (0.003)] l_pix: 4.3727e-03 
2024-04-23 13:39:32,716 INFO: [HAT_P..][epoch:  0, iter:  25,400, lr:(3.345e-05,8.386e-06,)] [eta: 2 days, 22:53:02, time (data): 6.401 (0.003)] l_pix: 2.1202e-02 
2024-04-23 13:50:12,837 INFO: [HAT_P..][epoch:  0, iter:  25,500, lr:(3.333e-05,8.358e-06,)] [eta: 2 days, 22:42:11, time (data): 6.401 (0.003)] l_pix: 2.1033e-02 
2024-04-23 14:00:53,004 INFO: [HAT_P..][epoch:  0, iter:  25,600, lr:(3.322e-05,8.330e-06,)] [eta: 2 days, 22:31:20, time (data): 6.402 (0.003)] l_pix: 9.9235e-03 
2024-04-23 14:11:33,114 INFO: [HAT_P..][epoch:  0, iter:  25,700, lr:(3.310e-05,8.301e-06,)] [eta: 2 days, 22:20:29, time (data): 6.401 (0.003)] l_pix: 7.9258e-03 
2024-04-23 14:22:13,246 INFO: [HAT_P..][epoch:  0, iter:  25,800, lr:(3.299e-05,8.273e-06,)] [eta: 2 days, 22:09:39, time (data): 6.401 (0.003)] l_pix: 7.2742e-03 
2024-04-23 14:32:53,366 INFO: [HAT_P..][epoch:  0, iter:  25,900, lr:(3.288e-05,8.245e-06,)] [eta: 2 days, 21:58:48, time (data): 6.401 (0.003)] l_pix: 8.2401e-03 
2024-04-23 14:43:33,528 INFO: [HAT_P..][epoch:  0, iter:  26,000, lr:(3.276e-05,8.216e-06,)] [eta: 2 days, 21:47:57, time (data): 6.402 (0.003)] l_pix: 2.0747e-02 
2024-04-23 14:43:33,528 INFO: Saving models and training states.
2024-04-23 14:54:13,777 INFO: [HAT_P..][epoch:  0, iter:  26,100, lr:(3.265e-05,8.188e-06,)] [eta: 2 days, 21:37:07, time (data): 6.401 (0.003)] l_pix: 4.2973e-03 
2024-04-23 15:04:53,922 INFO: [HAT_P..][epoch:  0, iter:  26,200, lr:(3.253e-05,8.159e-06,)] [eta: 2 days, 21:26:16, time (data): 6.401 (0.003)] l_pix: 5.8990e-03 
2024-04-23 15:15:34,096 INFO: [HAT_P..][epoch:  0, iter:  26,300, lr:(3.242e-05,8.130e-06,)] [eta: 2 days, 21:15:26, time (data): 6.402 (0.003)] l_pix: 7.8774e-03 
2024-04-23 15:26:14,215 INFO: [HAT_P..][epoch:  0, iter:  26,400, lr:(3.230e-05,8.102e-06,)] [eta: 2 days, 21:04:36, time (data): 6.401 (0.003)] l_pix: 8.9527e-03 
2024-04-23 15:36:54,327 INFO: [HAT_P..][epoch:  0, iter:  26,500, lr:(3.219e-05,8.073e-06,)] [eta: 2 days, 20:53:46, time (data): 6.401 (0.003)] l_pix: 4.7859e-03 
2024-04-23 15:47:34,462 INFO: [HAT_P..][epoch:  0, iter:  26,600, lr:(3.207e-05,8.044e-06,)] [eta: 2 days, 20:42:55, time (data): 6.402 (0.003)] l_pix: 4.5935e-03 
2024-04-23 15:58:14,636 INFO: [HAT_P..][epoch:  0, iter:  26,700, lr:(3.195e-05,8.016e-06,)] [eta: 2 days, 20:32:05, time (data): 6.402 (0.003)] l_pix: 1.0648e-02 
